\chapter{经典论文}
\section{YouTube}
\subsection{YouTube DNN}
文献 \citerb{2016-Youtube-DNN} 介绍了 DNN 在 YouTube 视频推荐上的应用。

\subsubsection{推荐模型整体结构}
YouTube DNN 推荐模型的整体结构如图~\ref{fig:youtube-dnn-structure}~所示，包括召
回和排序两级模型：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/YouTube/YouTube-DNN-推荐模型结构.pdf}
  \caption{YouTube DNN 推荐模型结构}\label{fig:youtube-dnn-structure}
\end{figure}

\begin{itemize}
  \item 召回模型：主要利用用户的历史信息，从视频库中的几百万视频中挑出几百个用户感
    兴趣的视频。
  \item 排序模型：综合利用用户的历史信息和视频特征，将召回模型的输出和其他来源的
    视频进行排序，最终输出十个左右的候选视频。
\end{itemize}

\subsubsection{召回模型结构}
召回模型将挑出用户感兴趣的视频建模成一个多分类问题：

\begin{equation}
  P(w_t=i|U, C) = \frac{e^{v_i u}}{\sum_{j \in V} e^{v_j u}}
\end{equation}

其中 $u$ 和 $v$ 分别为用户及其历史行为和视频的 embedding。模型结构如
图~\ref{fig:youtube-dnn-retrieval-structure}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/YouTube/YouTube-DNN-召回模型结构.pdf}
  \caption{YouTube DNN 召回模型结构}\label{fig:youtube-dnn-retrieval-structure}
\end{figure}

\paragraph{模型输入 feature}
\begin{itemize}
  \item 用户观看历史：首先将变长稀疏的 video ID 观看历史映射为 embedding，再将
    embedding 做平均得到固定长度的输入。
  \item 用户搜索历史：处理方法与用户观看历史类似。
  \item 用户个人信息：包括用户地理信息和设备的 embedding 以及归一化的用户性别、年
    龄、登录状态等。
  \item example age：模型预测时刻距离训练样本产生的时间。
\end{itemize}
\paragraph{正负样本} 用户完整看完一个视频作为正样本。训练样本包含所有观看记录，包
括其他网站嵌入的 YouTube 视频。每个用户都生成相等数量的训练样本，以降低高活跃用户
的影响。
\paragraph{训练} 由于 softmax 的类别非常多（视频库中的视频数），训练时采用负类采
样 + 重要性加权的方式进行加速，不同时计算所有类别的 loss。
\paragraph{部署} 部署时不需要计算 softmax，在内积空间使用近似最近邻方法寻找 top
N 的视频。
\paragraph{评测} 模型使用的训练样本只包括 $t$ 时间前的样本，预测 $t$ 时刻的召回
样本，以避免随机留一法导致的信息泄露。

\subsubsection{排序模型结构}
排序模型的目标是根据用户的期望观看时长对视频排序，其模型结构如
图~\ref{fig:youtube-dnn-structure}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/YouTube/YouTube-DNN-排序模型结构.pdf}
  \caption{YouTube DNN 排序模型结构}\label{fig:youtube-dnn-ranking-structure}
\end{figure}

\paragraph{模型输入 feature}
\begin{itemize}
  \item 视频 ID：综合展示的视频和用户观看的视频生成 embedding，取平均后作为输入。
    计算 embedding 时只考虑 top N 个。网络中涉及视频的 embedding 全部共享，提升
    泛化能力和训练速度，减少内存开销。
  \item 语言：综合用户语言和视频语言生成 embedding。
  \item 距上次观看的时间：先利用累积分布函数做归一化，同时引入非线性的平方项和开
    方项，增强模型表达能力。
  \item 之前展示的视频数：与距上次观看的时间处理类似。
\end{itemize}

\paragraph{特征工程}
\begin{itemize}
  \item 用户兴趣：用户在该频道看过的视频数、上次观看该频道的时间
  \item 召回模型信息：视频来源、召回模型输出的分数
  \item 视频展示频率：降低已展示未点击视频的出现频率
\end{itemize}

\paragraph{训练和部署} 排序模型的数学形式为带权重的逻辑回归，其中正样本为用户点击
展示的视频，其权重为观看时长；负样本为用户未点击展示的视频，其权重为 1。部署时，
使用 $e^{x}$，其中 $x$ 为逻辑回归模型的输出，$e^x$ 为每个视频的用户期望观看时长。

\subsection{YouTube MMoE Ranking}
文献 \citerb{2019-Youtube-MMoE} 介绍了 YouTube 使用 MMoE (Multi-gate
Mixture-of-Experts) 网络作为排序主网络，同时利用 shallow tower 缓解 selection
bias 的方法。

\subsubsection{MMoE 排序网络}
传统多任务学习网络的结构，一般是网络底层所有 layer 共享，在最后一层共享 layer 之
上分出不同任务的 branch。MMoE 网络结构如图~\ref{fig:mmoe-structure}~所示，在最后
一层共享 layer 之上，加入多个 expert block，同时对于每个 task，单独学习一
个 gating 网络，用于不同 expert 输出结果的加权，再将结果作为不同 task branch 的输
入。其中 gating 网络的输入同时包括各个 expert block 的输出，以及最后一层共
享 layer 的输出。

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/YouTube/YouTube-MMoE-网络结构.pdf}
  \caption{传统多任务学习网络与 MMoE 网络结构对比}\label{fig:mmoe-structure}
\end{figure}

网络同时预测分类和回归任务，分类任务包括是否点击，回归任务包括观看时长，将不同预
测综合计算排序得分，但论文中没有给出具体的计算公式。分类任务用交叉熵 loss，回归
任务用 L2 loss。

\subsubsection{缓解 selection bias}
为了缓解用户对当前排序系统给出结果的 selection bias，即当前排序系统给出的靠前 item 的
点击率更高，论文中用一个 shallow tower 预测一个 offset，在 engagement 相关预测的
sigmoid 之前，将 offset 作为修正量与预测结果相加。

\section{Airbnb}

\section{Facebook}

\section{阿里巴巴}
\subsection{COLD}
文献 \citerb{2020-Alibaba-COLD} 中介绍了阿里广告团队提出的粗排网络结构 COLD，其
优势包括。

%%% Local Variables:
%%% TeX-master: "../master"
%%% End:
